{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Recentaly/GPT-for-AI-sites/blob/main/Copy_of_Llama_for_AI_sites.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5X7sR9h_DUy"
      },
      "source": [
        "<h1><u><b>Free Llama LLM host on google colab (server side)</b></u></h1>\n",
        "\n",
        "<strong><u><h2>API status:</h2></u></strong>\n",
        "<p><strong>11/7/2023: Working ✅</strong></p>\n",
        "\n",
        "<strong><u><h2>How to start:</h2></u></strong>\n",
        "\n",
        "Firstly, if you are on mobile, run the audio file below and let it play in the background (it's an empty mp3 file).\n",
        "\n",
        "1. Run the code block below. It will install all neccessary modules\n",
        "\n",
        "2. Then execute the code block below that one\n",
        "\n",
        "3. A URL will pop out (with the domain ``trycloudflare.com``). Do not quit the second code block.\n",
        "\n",
        " (If more than one URL pops out, always use the topmost one. The second one usually doesn't work but if it does and the first one doesn't, you may use it.)\n",
        "\n",
        "4. Use that URL as an ``OpenAI reverse proxy`` (Do not use the local url which is ``127.0.0.1:5000``, it doesn't work)\n",
        "\n",
        "<br>\n",
        "\n",
        "<strong><u><h2>Model status:</h2></u></strong>\n",
        "<h4>Llama-2-70b-chat: ✅ </h4>\n",
        "<h4>Llama-2-13b-chat: ✅ </h4>\n",
        "<h4>Llama-2-7b-chat: ✅</h4>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<strong><u><h2>Other information:</h2></u></strong>\n",
        "**1. If you get error 103 (Argo Tunnel error), restart the second code block**\n",
        "\n",
        "**2. As long as a URL does appear, ignore any error in *white* text in the console. Report any errors in <strong>purple</strong>**\n",
        "\n",
        "**3. If none of the URL's work, stop the exeuction, reload the page and try again from the start. alternatively, you can delete the runtime and run both blocks again**\n",
        "\n",
        "<strong><u><h2>FAQ:</h2></u></strong>\n",
        "1. <p>Why did you switch from OpenAI models to Llama models?</p>\n",
        "<p>-> Llama models are easier to jailbreak</p>\n",
        "<p>-> The reverse-engineered OpenAI era is very new and constantly breaking. By using these models which I can reverse-engineer myself, I can assure higher uptime and reliability</p>\n",
        "\n",
        "2. <p>What's the difference between the models?</p>\n",
        "<p>-> A higher number means higher parameter count which means the model has been trained with more training data and thus might be smarter and generate longer replies</p>\n",
        "<p>-> However, the smaller of a model you choose, the quicker your response will generate</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ewkXkyiFP2Hq",
        "outputId": "17048eee-2eff-41b7-c7be-3a0f7733b0c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<b>Press play on the music player to keep the tab alive, then start KoboldAI below (Uses only 13MB of data)</b><br/>\n",
              "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title <-- Tap this if you're' on Mobile { display-mode: \"form\" }\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start the code blocks below (Uses only 13MB of data, credits to KoboldAI)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1am1-IRC-J0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab026ca-467c-40fc-f3ba-84e665f97c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages\n",
            "/content\n",
            "Cloning into 'Llama-for-AI-sites'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 145 (delta 7), reused 0 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (145/145), 52.72 KiB | 3.10 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/Llama-for-AI-sites\n",
            "Requirement already satisfied: flask[async] in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.2.5)\n",
            "Requirement already satisfied: flask_cors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: Requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: flask_cloudflared in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.0.14)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask[async]->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask[async]->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask[async]->-r requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask[async]->-r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: asgiref>=3.2 in /usr/local/lib/python3.10/dist-packages (from flask[async]->-r requirements.txt (line 1)) (3.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from Requests->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from Requests->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from Requests->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from Requests->-r requirements.txt (line 3)) (2023.7.22)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->-r requirements.txt (line 4)) (2023.6.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref>=3.2->flask[async]->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask[async]->-r requirements.txt (line 1)) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "# set the current work directory to the site packages to see if they're all installed THERE instead of in /content\n",
        "%cd /usr/local/lib/python3.10/dist-packages\n",
        "\n",
        "# then we go back to content\n",
        "%cd /content/\n",
        "\n",
        "# delete the script folder if it already exists (in case we need to update)\n",
        "!rm -rf Llama-for-AI-sites/\n",
        "\n",
        "# clone the repository where the server is\n",
        "!git clone https://github.com/Recentaly/Llama-for-AI-sites.git\n",
        "\n",
        "# set the directory to the downloaded github repo\n",
        "%cd Llama-for-AI-sites\n",
        "\n",
        "# now we install the server's required modules\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu9v0Iei9vE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26573b2a-0dcd-49a6-b305-56b116e03b39"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app 'main'\n",
            " * Debug mode: off\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            " * Running on https://either-indonesian-coleman-having.trycloudflare.com\n",
            " * Traffic stats available on http://127.0.0.1:8268/metrics\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2023 22:19:08] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2023 22:19:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [11/Nov/2023 22:19:12] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "# run the server\n",
        "!python main.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwzwrq7U2LnL93RelR0OVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}